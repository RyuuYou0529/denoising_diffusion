{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryuuyou/.conda/envs/dm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import utils\n",
    "\n",
    "import math\n",
    "\n",
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer, Sampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(\n",
    "    dim = 64,\n",
    "    channels=1,\n",
    "    dim_mults = (1, 2, 4, 8)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = 128,\n",
    "    timesteps = 1000,\n",
    "    sampling_timesteps = 1000,\n",
    "    loss_type = 'l1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler(diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from version 1.5.4\n"
     ]
    }
   ],
   "source": [
    "path = 'results_x/model-15.pt'\n",
    "sampler.load(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step:  10%|â–‰         | 97/1000 [08:37<1:20:21,  5.34s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_images \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39;49msample()\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/sampler.py:80\u001b[0m, in \u001b[0;36mSampler.sample\u001b[0;34m(self, num_samples, batch_size, return_all_timesteps, return_ndarr)\u001b[0m\n\u001b[1;32m     77\u001b[0m batches \u001b[39m=\u001b[39m num_to_groups(num_samples, batch_size)\n\u001b[1;32m     79\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 80\u001b[0m     all_images_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m n: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mema\u001b[39m.\u001b[39;49mema_model\u001b[39m.\u001b[39;49msample(batch_size\u001b[39m=\u001b[39;49mn, return_all_timesteps\u001b[39m=\u001b[39;49mreturn_all_timesteps), batches))\n\u001b[1;32m     81\u001b[0m all_images \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(all_images_list, dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m return_all_timesteps:\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/sampler.py:80\u001b[0m, in \u001b[0;36mSampler.sample.<locals>.<lambda>\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     77\u001b[0m batches \u001b[39m=\u001b[39m num_to_groups(num_samples, batch_size)\n\u001b[1;32m     79\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 80\u001b[0m     all_images_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m n: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mema\u001b[39m.\u001b[39;49mema_model\u001b[39m.\u001b[39;49msample(batch_size\u001b[39m=\u001b[39;49mn, return_all_timesteps\u001b[39m=\u001b[39;49mreturn_all_timesteps), batches))\n\u001b[1;32m     81\u001b[0m all_images \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(all_images_list, dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m return_all_timesteps:\n",
      "File \u001b[0;32m~/.conda/envs/dm/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:697\u001b[0m, in \u001b[0;36mGaussianDiffusion.sample\u001b[0;34m(self, batch_size, return_all_timesteps)\u001b[0m\n\u001b[1;32m    695\u001b[0m image_size, channels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannels\n\u001b[1;32m    696\u001b[0m sample_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_sample_loop \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_ddim_sampling \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mddim_sample\n\u001b[0;32m--> 697\u001b[0m \u001b[39mreturn\u001b[39;00m sample_fn((batch_size, channels, image_size, image_size), return_all_timesteps \u001b[39m=\u001b[39;49m return_all_timesteps)\n",
      "File \u001b[0;32m~/.conda/envs/dm/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:643\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample_loop\u001b[0;34m(self, shape, return_all_timesteps)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tqdm(\u001b[39mreversed\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps)), desc \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msampling loop time step\u001b[39m\u001b[39m'\u001b[39m, total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps):\n\u001b[1;32m    642\u001b[0m     self_cond \u001b[39m=\u001b[39m x_start \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_condition \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m     img, x_start \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp_sample(img, t, self_cond)\n\u001b[1;32m    644\u001b[0m     imgs\u001b[39m.\u001b[39mappend(img)\n\u001b[1;32m    646\u001b[0m ret \u001b[39m=\u001b[39m img \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_all_timesteps \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mstack(imgs, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/dm/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:627\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample\u001b[0;34m(self, x, t, x_self_cond)\u001b[0m\n\u001b[1;32m    625\u001b[0m b, \u001b[39m*\u001b[39m_, device \u001b[39m=\u001b[39m \u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape, x\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    626\u001b[0m batched_times \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((b,), t, device \u001b[39m=\u001b[39m device, dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m--> 627\u001b[0m model_mean, _, model_log_variance, x_start \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp_mean_variance(x \u001b[39m=\u001b[39;49m x, t \u001b[39m=\u001b[39;49m batched_times, x_self_cond \u001b[39m=\u001b[39;49m x_self_cond, clip_denoised \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    628\u001b[0m noise \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn_like(x) \u001b[39mif\u001b[39;00m t \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0.\u001b[39m \u001b[39m# no noise if t == 0\u001b[39;00m\n\u001b[1;32m    629\u001b[0m pred_img \u001b[39m=\u001b[39m model_mean \u001b[39m+\u001b[39m (\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m model_log_variance)\u001b[39m.\u001b[39mexp() \u001b[39m*\u001b[39m noise\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:614\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[0;34m(self, x, t, x_self_cond, clip_denoised)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mp_mean_variance\u001b[39m(\u001b[39mself\u001b[39m, x, t, x_self_cond \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, clip_denoised \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 614\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_predictions(x, t, x_self_cond)\n\u001b[1;32m    615\u001b[0m     x_start \u001b[39m=\u001b[39m preds\u001b[39m.\u001b[39mpred_x_start\n\u001b[1;32m    617\u001b[0m     \u001b[39mif\u001b[39;00m clip_denoised:\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:589\u001b[0m, in \u001b[0;36mGaussianDiffusion.model_predictions\u001b[0;34m(self, x, t, x_self_cond, clip_x_start, rederive_pred_noise)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_predictions\u001b[39m(\u001b[39mself\u001b[39m, x, t, x_self_cond \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, clip_x_start \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, rederive_pred_noise \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 589\u001b[0m     model_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x, t, x_self_cond)\n\u001b[1;32m    590\u001b[0m     maybe_clip \u001b[39m=\u001b[39m partial(torch\u001b[39m.\u001b[39mclamp, \u001b[39mmin\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1.\u001b[39m, \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m) \u001b[39mif\u001b[39;00m clip_x_start \u001b[39melse\u001b[39;00m identity\n\u001b[1;32m    592\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpred_noise\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/dm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:376\u001b[0m, in \u001b[0;36mUnet.forward\u001b[0;34m(self, x, time, x_self_cond)\u001b[0m\n\u001b[1;32m    373\u001b[0m h\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m    375\u001b[0m x \u001b[39m=\u001b[39m block2(x, t)\n\u001b[0;32m--> 376\u001b[0m x \u001b[39m=\u001b[39m attn(x)\n\u001b[1;32m    377\u001b[0m h\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m    379\u001b[0m x \u001b[39m=\u001b[39m downsample(x)\n",
      "File \u001b[0;32m~/.conda/envs/dm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:86\u001b[0m, in \u001b[0;36mResidual.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39m+\u001b[39m x\n",
      "File \u001b[0;32m~/.conda/envs/dm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:133\u001b[0m, in \u001b[0;36mPreNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 133\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm(x)\n\u001b[1;32m    134\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(x)\n",
      "File \u001b[0;32m~/.conda/envs/dm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/share_ssd/ryuuyou/denoising-diffusion/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py:123\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m eps \u001b[39m=\u001b[39m \u001b[39m1e-5\u001b[39m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat32 \u001b[39melse\u001b[39;00m \u001b[39m1e-3\u001b[39m\n\u001b[1;32m    122\u001b[0m var \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mvar(x, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, unbiased \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, keepdim \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 123\u001b[0m mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmean(x, dim \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, keepdim \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m (x \u001b[39m-\u001b[39m mean) \u001b[39m*\u001b[39m (var \u001b[39m+\u001b[39m eps)\u001b[39m.\u001b[39mrsqrt() \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_images = sampler.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = utils.make_grid(all_images, nrow=int(np.sqrt(25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image = all_images[0].cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
